{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The project: Predict travel insurance claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"Travel Insurance\" dataset from Zahier Nasrudin, published on Kaggle. It contains data from a third-party insurance servicing company based in Singapore. The data contains information on travel insurance holders, some of the holder's attributes, and some attributes of the insurance products purchased by the holders. The target is a binary variable, stating whether a policyholder filed a claim against the insurance company. <br>\n",
    "Link to data: https://www.kaggle.com/datasets/mhdzahier/travel-insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For .info() method to run below, need to older version of numpy\n",
    "!pip install numpy==1.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from platform import python_version\n",
    "import zipfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_version(), np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download data from Kaggle into Jupyter NB instance folder, load data into Jupyter NB environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Download the authentication json file ('kaggle.json') from Kaggle & upload it to the notebook file directory <br>\n",
    "(2) Run the following code in bash terminal to download the travel insurance dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kaggle\n",
    "# mkdir ~/.kaggle\n",
    "# cp kaggle.json ~/.kaggle/\n",
    "# chmod 600 .kaggle/kaggle.json\n",
    "# cd ml_eng_capstone\n",
    "# kaggle datasets download -d mhdzahier/travel-insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data persisted on Jupyter notebook instance into Jupyter notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('travel-insurance.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "travel_insurance_df = pd.read_csv('travel insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Describe & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duration:')\n",
    "print(travel_insurance_df['Duration'].describe())\n",
    "print()\n",
    "print('Commision (in value):')\n",
    "print(travel_insurance_df['Commision (in value)'].describe())\n",
    "print()\n",
    "print('Age:')\n",
    "print(travel_insurance_df['Age'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop rows with negative duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(travel_insurance_df[travel_insurance_df['Duration']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_neg_duration = travel_insurance_df[travel_insurance_df['Duration']<0].index\n",
    "travel_insurance_df.drop(index_neg_duration, inplace=True)\n",
    "travel_insurance_df = travel_insurance_df.reset_index().drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NAs (only in Gender column) by string 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.fillna('UNKNOWN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove rows with missing data:\n",
    "#travel_insurance_df = travel_insurance_df.dropna()\n",
    "#travel_insurance_df = travel_insurance_df.reset_index().drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview over data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_instances = travel_insurance_df.shape[0]\n",
    "no_features = len(travel_insurance_df.columns) - 1\n",
    "target_shares = round(travel_insurance_df['Claim'].value_counts()/len(travel_insurance_df),3)\n",
    "print(\"No. of instances: \" + f\"{no_instances:,}\")\n",
    "print(\"No. of columns: \" + str(no_features))\n",
    "print(\"Share of targets: \\n\" + str(target_shares))\n",
    "travel_insurance_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Prep data, save on Jupyter NB instance, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode target ('Claim') into numerical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {'Yes' : 1, 'No' : 0}\n",
    "travel_insurance_df['Claim'] = travel_insurance_df['Claim'].replace(dict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace categorical features through one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df):\n",
    "    #Function performs one-hot encoding with features of datatype object (string)\n",
    "    #Last dummy column of each categorical is excluded to avoid perfect collinearity\n",
    "    #NOTE: Categorical features already encoded as integers are NOT identified by this function!\n",
    "    dtypes_ser = df.dtypes\n",
    "    dtypes_df = dtypes_ser.to_frame().reset_index()\n",
    "    dtypes_df = dtypes_df.rename(columns = {'index':'column', 0:'dtype'})\n",
    "    categ_list = list(dtypes_df['column'][dtypes_df['dtype']=='object'])\n",
    "    for feat in categ_list:\n",
    "        one_hot = pd.get_dummies(df[feat], prefix=feat, drop_first=True)\n",
    "        df = df.join(one_hot)\n",
    "        df.drop(feat, inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df = one_hot(travel_insurance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split <br>\n",
    "(Note: test data is without label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train, travel_insurance_df_test = train_test_split(travel_insurance_df, test_size = 0.2, \n",
    "                                                                 stratify = travel_insurance_df['Claim'], \n",
    "                                                                 shuffle = True, \n",
    "                                                                 random_state = 1)\n",
    "travel_insurance_df_test = travel_insurance_df_test.drop(labels='Claim', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train.shape, travel_insurance_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_train = np.array(travel_insurance_df_train)\n",
    "travel_insurance_test = np.array(travel_insurance_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save train and test data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.Session()\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "bucket = sm_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session, sm_role, bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../ml_eng_capstone/data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train.to_csv(data_dir + '/' + 'train.csv', header = False, index = False)\n",
    "travel_insurance_df_test.to_csv(data_dir + '/' + 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'travel_insurance_claim_data'\n",
    "train_path_s3 = sm_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "test_path_s3 = sm_session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_list = []\n",
    "for i in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    bucket_list.append(i)\n",
    "bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete data files in s3://sagemaker-us-east-1-786251868139/travel_insurance_claim_data/\n",
    "# boto3.resource('s3').Bucket(bucket).objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\tTrain Random Forest w custom scikit-learn estimator (baseline A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rf_base = SKLearn(entry_point = 'train.py',\n",
    "                       source_dir = 'source',\n",
    "                       role = sm_role,\n",
    "                       framework_version = '0.23-1',\n",
    "                       py_version = 'py3',\n",
    "                       instance_count = 1,\n",
    "                       instance_type = 'ml.m4.xlarge',\n",
    "                       output_path = 's3://{}/{}/output'.format(bucket, prefix),\n",
    "                       sagemaker_session = sm_session\n",
    "                       #hyperparameters = {'n_estimators':100, 'min_samples_split':2, 'min_samples_leaf':1, 'max_depth':None, 'max_leaf_nodes':None}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rf_base.fit({'train' : train_path_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Train SVM w custom scikit-learn estimator (baseline B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Test baseline models with batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Train Random Forest w re-sampled training data (SMOTE-Tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Train SVM w re-sampled training data (SMOTE-Tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Test models with re-sampled training data with batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (j) Train Random Forest w re-sampled training data + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (k) Train SVM w re-sampled training data + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (l) Deploy models from (j), (k) behind multi-model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (m) Run A/B Test with multi-model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
