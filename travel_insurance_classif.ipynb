{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The project: Predict travel insurance claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"Travel Insurance\" dataset from Zahier Nasrudin, published on Kaggle. It contains data from a third-party insurance servicing company based in Singapore. The data contains information on travel insurance holders, some of the holder's attributes, and some attributes of the insurance products purchased by the holders. The target is a binary variable, stating whether a policyholder filed a claim against the insurance company. <br>\n",
    "Link to data: https://www.kaggle.com/datasets/mhdzahier/travel-insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18.1 in /opt/conda/lib/python3.7/site-packages (1.18.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# For .info() method to run below, need to older version of numpy\n",
    "!pip install numpy==1.18.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from platform import python_version\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "import os\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.sklearn.estimator import SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3.7.10', '1.18.1')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_version(), np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download data from Kaggle into Jupyter NB instance folder, load data into Jupyter NB environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Download the authentication json file ('kaggle.json') from Kaggle & upload it to the notebook file directory <br>\n",
    "(2) Run the following code in bash terminal to download the travel insurance dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kaggle\n",
    "# mkdir ~/.kaggle\n",
    "# cp kaggle.json ~/.kaggle/\n",
    "# chmod 600 .kaggle/kaggle.json\n",
    "# cd ml_eng_capstone\n",
    "# kaggle datasets download -d mhdzahier/travel-insurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data persisted on Jupyter notebook instance into Jupyter notebook environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('travel-insurance.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall()\n",
    "travel_insurance_df = pd.read_csv('travel insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Inspect & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe numerical values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Duration:')\n",
    "print(travel_insurance_df['Duration'].describe())\n",
    "print()\n",
    "print('Commision (in value):')\n",
    "print(travel_insurance_df['Commision (in value)'].describe())\n",
    "print()\n",
    "print('Age:')\n",
    "print(travel_insurance_df['Age'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_sub = travel_insurance_df[['Duration', 'Net Sales', 'Commision (in value)', 'Age']]\n",
    "for i, col in enumerate(travel_insurance_sub):\n",
    "    plt.figure(i)\n",
    "    sns.distplot(travel_insurance_sub[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration: Drop rows with negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(travel_insurance_df[travel_insurance_df['Duration']<0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_neg_duration = travel_insurance_df[travel_insurance_df['Duration']<0].index\n",
    "travel_insurance_df.drop(index_neg_duration, inplace=True)\n",
    "travel_insurance_df = travel_insurance_df.reset_index().drop(labels='index', axis=1)\n",
    "travel_insurance_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duration: Drop rows with extremely high values (upward outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "travel_insurance_df['Duration'].value_counts().sort_index(ascending = False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_high_duration = travel_insurance_df[travel_insurance_df['Duration']>500].index\n",
    "travel_insurance_df.drop(index_high_duration, inplace=True)\n",
    "travel_insurance_df = travel_insurance_df.reset_index().drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df['Age'].value_counts().sort_index(ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upward outliers in age (118) will be replaced by next best \"realistic\" value (88), effectively introducing an age cap at 88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df['Age'] = np.where(travel_insurance_df['Age'] == 118, 88, travel_insurance_df['Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace NAs (only in Gender column) by string 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.fillna('UNKNOWN',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Remove rows with missing data:\n",
    "#travel_insurance_df = travel_insurance_df.dropna()\n",
    "#travel_insurance_df = travel_insurance_df.reset_index().drop(labels='index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview over data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_instances = travel_insurance_df.shape[0]\n",
    "no_features = len(travel_insurance_df.columns) - 1\n",
    "target_shares = round(travel_insurance_df['Claim'].value_counts()/len(travel_insurance_df),3)\n",
    "print(\"No. of instances: \" + f\"{no_instances:,}\")\n",
    "print(\"No. of columns: \" + str(no_features))\n",
    "print(\"Share of targets: \\n\" + str(target_shares))\n",
    "travel_insurance_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['Agency', 'Agency Type', 'Distribution Channel', 'Product Name', 'Destination']\n",
    "for feat in feat_list:\n",
    "    print('Value count for feature: ' + feat)\n",
    "    print(travel_insurance_df[feat].value_counts().head(50))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'Agency', 'Agency Type', 'Distribution Channel', 'Product Name', 'Destination'\n",
    "travel_insurance_df['Destination'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Prep data, save on Jupyter NB instance, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recode target ('Claim') into numerical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_label = {'Yes' : 1, 'No' : 0}\n",
    "travel_insurance_df['Claim'] = travel_insurance_df['Claim'].replace(dict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation analysis of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.crosstab(travel_insurance_df['Agency'], travel_insurance_df['Agency Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace categorical features through one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical features are transformed into dummy variables. Given the non-ordinal nature of the categorical features ('Agency', 'Agency Type', 'Distribution Channel', 'Product Name', 'Destination', 'Gender') we use one-hot encoding instead of label encoding. The last dummy column of each categorical feature is excluded to avoid perfect collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(df):lit\n",
    "    #Function performs one-hot encoding with features of datatype object (string)lit\n",
    "    #Last dummy column of each categorical feature is excluded to avoid perfect collinearity\n",
    "    #NOTE: Categorical features already encoded as integers are NOT identified by this function!\n",
    "    dtypes_ser = df.dtypes\n",
    "    dtypes_df = dtypes_ser.to_frame().reset_index()\n",
    "    dtypes_df = dtypes_df.rename(columns = {'index':'column', 0:'dtype'})\n",
    "    categ_list = list(dtypes_df['column'][dtypes_df['dtype']=='object'])\n",
    "    for feat in categ_list:\n",
    "        one_hot = pd.get_dummies(df[feat], prefix=feat, drop_first=True)\n",
    "        df = df.join(one_hot)\n",
    "        df.drop(feat, inplace=True, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df = one_hot(travel_insurance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test split <br>\n",
    "(Note: test data is without label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train, travel_insurance_df_test = train_test_split(travel_insurance_df, test_size = 0.2, \n",
    "                                                                 stratify = travel_insurance_df['Claim'], \n",
    "                                                                 shuffle = True, \n",
    "                                                                 random_state = 1)\n",
    "travel_insurance_df_test_x = travel_insurance_df_test.drop(labels='Claim', axis = 1)\n",
    "travel_insurance_df_test_y = travel_insurance_df_test['Claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train.shape, travel_insurance_df_test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save train and test data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_session = sagemaker.Session()\n",
    "sm_role = sagemaker.get_execution_role()\n",
    "bucket = sm_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<sagemaker.session.Session at 0x7f454f75d890>,\n",
       " 'arn:aws:iam::786251868139:role/c20300a265023u1382356t1w7-SageMakerNotebookInstanc-OA3L97SSKD0B',\n",
       " 'sagemaker-us-east-1-786251868139')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_session, sm_role, bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../ml_eng_capstone/data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_insurance_df_train.to_csv(data_dir + '/' + 'train.csv', header = False, index = False)\n",
    "travel_insurance_df_test_x.to_csv(data_dir + '/' + 'test.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'travel_insurance_claim_data'\n",
    "train_path_s3 = sm_session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)\n",
    "test_path_s3 = sm_session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_list = []\n",
    "for i in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    bucket_list.append(i)\n",
    "bucket_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete data files in s3://sagemaker-us-east-1-786251868139/travel_insurance_claim_data/\n",
    "#boto3.resource('s3').Bucket(bucket).objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d)\tTrain Random Forest w custom scikit-learn estimator (baseline A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train_rf.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rf_base = SKLearn(entry_point = 'train_rf.py',\n",
    "                       source_dir = 'source',\n",
    "                       role = sm_role,\n",
    "                       framework_version = '0.23-1',\n",
    "                       py_version = 'py3',\n",
    "                       instance_count = 1,\n",
    "                       instance_type = 'ml.m4.xlarge',\n",
    "                       output_path = 's3://{}/{}/output'.format(bucket, prefix),\n",
    "                       sagemaker_session = sm_session\n",
    "                       #hyperparameters = {'n_estimators':100, 'min_samples_split':2, 'min_samples_leaf':1, 'max_depth':None, 'max_leaf_nodes':None}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_rf_base.fit({'train' : train_path_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Train SVM w custom scikit-learn estimator (baseline B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize source/train_svm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_svm_base = SKLearn(entry_point = 'train_svm.py',\n",
    "                       source_dir = 'source',\n",
    "                       role = sm_role,\n",
    "                       framework_version = '0.23-1',\n",
    "                       py_version = 'py3',\n",
    "                       instance_count = 1,\n",
    "                       instance_type = 'ml.m4.xlarge',\n",
    "                       output_path = 's3://{}/{}/output'.format(bucket, prefix),\n",
    "                       sagemaker_session = sm_session\n",
    "                       #hyperparameters = {'C':1, 'gamma':0.01}\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_svm_base.fit({'train' : train_path_s3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Test baseline models with batch transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f-1) Test RF model (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch transform with SageMaker SDK (needs estimator_obj in notebook environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_obj_rf = est_rf_base.transformer(instance_count = 1, \n",
    "                                           instance_type = 'ml.m4.xlarge')\n",
    "transform_obj_rf.transform(test_path_s3, content_type = 'text/csv', split_type = 'Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_obj_rf.output_path, data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy predictions from batch transform job to Jupyter NB instance folder & rename file\n",
    "#!aws s3 cp --recursive $transform_obj_rf.output_path $data_dir\n",
    "#!mv data/test.csv.out data/base_rf_test.csv.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_base_rf = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n",
    "print('Accuracy is: ' + str(round(accuracy_score(travel_insurance_df_test_y, predictions_base_rf.transpose()),4)))\n",
    "print('Recall is: ' + str(round(recall_score(travel_insurance_df_test_y, predictions_base_rf.transpose()),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch transform with AWS Python SDK Boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training job name: sagemaker-scikit-learn-2022-05-15-15-09-22-292"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sm_session.sagemaker_client.describe_training_job(TrainingJobName='sagemaker-scikit-learn-2022-05-15-15-09-22-292')\n",
    "model_artifacts_paths3 = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "training_image = training_job_info['AlgorithmSpecification']['TrainingImage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\"Image\" : training_image, \n",
    "                     \"ModelDataUrl\" : model_artifacts_paths3}\n",
    "model_name= training_job_info['TrainingJobName'] + '-model'\n",
    "model_info = sm_session.sagemaker_client.create_model(ModelName = model_name,\n",
    "                                                      ExecutionRoleArn = sm_role,\n",
    "                                                      PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_job_name = training_job_info['TrainingJobName'] + '-transform-job'\n",
    "transform_output_path = \"s3://{}/{}/batch-transform/\".format(sm_session.default_bucket(),prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_request = {\n",
    "    \"TransformJobName\" : transform_job_name,\n",
    "    \"ModelName\" : model_name,\n",
    "    \"MaxConcurrentTransforms\": 1,\n",
    "    \"MaxPayloadInMB\" : 6,\n",
    "    \"BatchStrategy\" : \"MultiRecord\",\n",
    "    \"TransformOutput\" : {\n",
    "        \"S3OutputPath\" : transform_output_path\n",
    "    },\n",
    "    \"TransformInput\": {\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": test_path_s3,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TransformResources\": {\n",
    "        \"InstanceType\": \"ml.m4.xlarge\",\n",
    "        \"InstanceCount\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................."
     ]
    }
   ],
   "source": [
    "transform_response = sm_session.sagemaker_client.create_transform_job(**transform_request)\n",
    "transform_desc = sm_session.wait_for_transform_job(transform_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (f-2) Test SVM model (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to Kernel shutdown need to create batch transform job from training job run before (model artifacts stored on S3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job_info = sm_session.sagemaker_client.describe_training_job(TrainingJobName='sagemaker-scikit-learn-2022-05-15-15-30-29-785')\n",
    "model_artifacts_paths3 = training_job_info['ModelArtifacts']['S3ModelArtifacts']\n",
    "training_image = training_job_info['AlgorithmSpecification']['TrainingImage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_container = {\"Image\" : training_image, \n",
    "                     \"ModelDataUrl\" : model_artifacts_paths3}\n",
    "model_name= training_job_info['TrainingJobName'] + '-model'\n",
    "model_info = sm_session.sagemaker_client.create_model(ModelName = model_name,\n",
    "                                                      ExecutionRoleArn = sm_role,\n",
    "                                                      PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_job_name = training_job_info['TrainingJobName'] + '-transform-job'\n",
    "transform_output_path = \"s3://{}/{}/batch-transform/\".format(sm_session.default_bucket(),prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_request = {\n",
    "    \"TransformJobName\" : transform_job_name,\n",
    "    \"ModelName\" : model_name,\n",
    "    \"MaxConcurrentTransforms\": 1,\n",
    "    \"MaxPayloadInMB\" : 6,\n",
    "    \"BatchStrategy\" : \"MultiRecord\",\n",
    "    \"TransformOutput\" : {\n",
    "        \"S3OutputPath\" : transform_output_path\n",
    "    },\n",
    "    \"TransformInput\": {\n",
    "        \"ContentType\": \"text/csv\",\n",
    "        \"SplitType\": \"Line\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": test_path_s3,\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"TransformResources\": {\n",
    "        \"InstanceType\": \"ml.m4.xlarge\",\n",
    "        \"InstanceCount\": 1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_response = sm_session.sagemaker_client.create_transform_job(**transform_request)\n",
    "transform_desc = sm_session.wait_for_transform_job(transform_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: AWS CLI version 2, the latest major version of the AWS CLI, is now stable and recommended for general use. For more information, see the AWS CLI version 2 installation instructions at: https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n",
      "\n",
      "usage: aws [options] <command> <subcommand> [<subcommand> ...] [parameters]\n",
      "To see help text, you can run:\n",
      "\n",
      "  aws help\n",
      "  aws <command> help\n",
      "  aws <command> <subcommand> help\n",
      "aws: error: the following arguments are required: paths\n"
     ]
    }
   ],
   "source": [
    "# Copy predictions from batch transform job to Jupyter NB instance folder\n",
    "!aws s3 cp --recursive $transform_obj_svm.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_base_svm = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_obj_svm.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (g) Train Random Forest w re-sampled training data (SMOTE-Tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (h) Train SVM w re-sampled training data (SMOTE-Tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (i) Test models with re-sampled training data with batch transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i-1) Test RF model (re-sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (i-2) Test SVM model (re-sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (j) Train Random Forest w re-sampled training data + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (k) Train SVM w re-sampled training data + hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (l) Deploy models from (j), (k) behind multi-model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (m) Run A/B Test with multi-model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
